{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2fc031",
   "metadata": {},
   "source": [
    "# Few-Shot Training Workflow\n",
    "\n",
    "## Frame Sampling & Embedding\n",
    "\n",
    "### Input:\n",
    "- 7-second clips (goal/non-goal).\n",
    "\n",
    "### Action:\n",
    "1. Uniformly sample **N frames**:\n",
    "   - **16 frames** for ResNet-50.\n",
    "   - **32 frames** for R(2+1)D.\n",
    "2. Preprocess frames:\n",
    "   - Resize and normalize.\n",
    "3. Pass frames through a pretrained backbone:\n",
    "   - **ResNet-50** → 2048-dimensional feature vectors.\n",
    "   - **R(2+1)D-18** → 512-dimensional feature vectors.\n",
    "\n",
    "### Output:\n",
    "- Per-frame feature tensors.\n",
    "- Mean-pooled into one **2048-D** or **512-D** clip embedding saved as `.npy`.\n",
    "\n",
    "---\n",
    "\n",
    "## Prototype Construction\n",
    "\n",
    "### Input:\n",
    "- All training clip embeddings per class.\n",
    "\n",
    "### Action:\n",
    "1. Compute class “prototype”:\n",
    "   - Average all embeddings for each class.\n",
    "   - L2-normalize the resulting vectors.\n",
    "\n",
    "### Output:\n",
    "- Two normalized vectors:\n",
    "  - `proto_goal`\n",
    "  - `proto_nongoal`\n",
    "\n",
    "---\n",
    "\n",
    "## Few-Shot Classification\n",
    "\n",
    "### Input:\n",
    "- Test clip embedding.\n",
    "- Class prototypes (`proto_goal`, `proto_nongoal`).\n",
    "\n",
    "### Action:\n",
    "1. L2-normalize the test embedding.\n",
    "2. Compute cosine similarity to each prototype.\n",
    "3. Compare the difference in similarity to a threshold (Δ).\n",
    "\n",
    "### Output:\n",
    "- Predicted label: **\"Goal\"** or **\"Non-Goal\"**.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "### Input:\n",
    "- All test predictions with true labels.\n",
    "\n",
    "### Action:\n",
    "1. Compute:\n",
    "   - Confusion matrix.\n",
    "   - Precision, recall, F₁ score.\n",
    "   - Overall accuracy.\n",
    "2. Sweep Δ to find the best threshold.\n",
    "\n",
    "### Output:\n",
    "- Numeric metrics.\n",
    "- Per-clip similarity scores printed in the console.\n",
    "\n",
    "---\n",
    "\n",
    "## Few-Shot Approach\n",
    "\n",
    "This is a **prototype-based few-shot method**:\n",
    "- Each class is represented by a **mean feature vector**.\n",
    "- New clips are classified by their **cosine similarity** to these few-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d49cf",
   "metadata": {},
   "source": [
    "### Same frame level pre-Processing taken from (monday.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process the video to:\n",
    "    1. Convert to grayscale.\n",
    "    2. Remove grass and audience areas while preserving the ball.\n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Changed to mp4v for better compatibility\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=False)\n",
    "    \n",
    "    print(f\"Processing {total_frames} frames from {input_path}...\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Convert original frame to HSV for better color detection\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define green grass color range in HSV (more specific range)\n",
    "        lower_green = np.array([35, 40, 40])\n",
    "        upper_green = np.array([85, 255, 255])\n",
    "        grass_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "        # Define ball detection (white/light colored ball)\n",
    "        lower_ball_hsv = np.array([0, 0, 200])\n",
    "        upper_ball_hsv = np.array([180, 30, 255])\n",
    "        ball_mask_hsv = cv2.inRange(hsv, lower_ball_hsv, upper_ball_hsv)\n",
    "        \n",
    "        _, ball_mask_gray = cv2.threshold(gray_frame, 200, 255, cv2.THRESH_BINARY)\n",
    "        ball_mask = cv2.bitwise_or(ball_mask_hsv, ball_mask_gray)\n",
    "        \n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        ball_mask = cv2.morphologyEx(ball_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        ball_mask = cv2.morphologyEx(ball_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        lower_audience = np.array([0, 100, 150])\n",
    "        upper_audience = np.array([180, 255, 255])\n",
    "        audience_mask = cv2.inRange(hsv, lower_audience, upper_audience)\n",
    "        audience_mask = cv2.bitwise_and(audience_mask, cv2.bitwise_not(ball_mask))\n",
    "\n",
    "        combined_mask = cv2.bitwise_or(grass_mask, audience_mask)\n",
    "        keep_mask = cv2.bitwise_not(combined_mask)\n",
    "        keep_mask = cv2.bitwise_or(keep_mask, ball_mask)\n",
    "\n",
    "        processed_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=keep_mask)\n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Processed video saved as: {output_path}\")\n",
    "\n",
    "def process_all_videos(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process all videos in the input folder and save them to the output folder.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input videos.\n",
    "        output_folder (str): Path to the folder to save processed videos.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for video_file in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, video_file)\n",
    "        output_path = os.path.join(output_folder, video_file)\n",
    "        \n",
    "        if os.path.isfile(input_path) and video_file.endswith(\".mp4\"):\n",
    "            process_video(input_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input and output folders\n",
    "    base_path = \"F:/AIM Lab/Experiment/Clips\"\n",
    "    goal_input_folder = os.path.join(base_path, \"goal\")\n",
    "    no_goal_input_folder = os.path.join(base_path, \"no goal\")\n",
    "    goal_output_folder = os.path.join(base_path, \"Goal p1\")\n",
    "    no_goal_output_folder = os.path.join(base_path, \"NoGoal p1\")\n",
    "    \n",
    "    # Process videos in the \"goal\" folder\n",
    "    print(\"Processing videos in the 'goal' folder...\")\n",
    "    process_all_videos(goal_input_folder, goal_output_folder)\n",
    "    \n",
    "    # Process videos in the \"no goal\" folder\n",
    "    print(\"Processing videos in the 'no goal' folder...\")\n",
    "    process_all_videos(no_goal_input_folder, no_goal_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfffa0e",
   "metadata": {},
   "source": [
    "###  cell right below was not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ace926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing videos in the 'Goal p1' folder...\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g1.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g1\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g10.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g10\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g11.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g11\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g12.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g12\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g13.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g13\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g14.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g14\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g15.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g15\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g16.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g16\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g17.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g17\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g18.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g18\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g19.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g19\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g2.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g2\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g20.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g20\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g21.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g21\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g22.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g22\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g23.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g23\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g24.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g24\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g25.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g25\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g26.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g26\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g27.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g27\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g28.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g28\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g29.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g29\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g3.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g3\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g30.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g30\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g31.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g31\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g32.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g32\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g33.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g33\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g34.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g34\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g35.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g35\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g36.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g36\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g37.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g37\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g4.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g4\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g5.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g5\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g6.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g6\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g7.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g7\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g8.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g8\n",
      "Processed 15 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\g9.mp4 and saved to F:/AIM Lab/Experiment/Clips\\Goal p2\\g9\n",
      "Processing videos in the 'NoGoal p1' folder...\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng1.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng1\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng10.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng10\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng11.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng11\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng12.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng12\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng13.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng13\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng14.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng14\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng15.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng15\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng16.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng16\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng17.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng17\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng18.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng18\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng19.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng19\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng2.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng2\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng20.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng20\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng21.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng21\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng22.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng22\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng23.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng23\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng24.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng24\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng25.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng25\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng26.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng26\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng27.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng27\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng28.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng28\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng29.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng29\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng3.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng3\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng30.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng30\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng31.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng31\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng32.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng32\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng33.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng33\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng34.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng34\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng35.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng35\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng36.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng36\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng37.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng37\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng4.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng4\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng5.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng5\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng6.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng6\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng7.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng7\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng8.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng8\n",
      "Processed 13 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\ng9.mp4 and saved to F:/AIM Lab/Experiment/Clips\\NoGoal p2\\ng9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_and_process_frames(video_path, output_folder, fps=2, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at a specified FPS, resize, and save them.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_folder (str): Path to the folder to save processed frames.\n",
    "        fps (int): Frames per second to extract.\n",
    "        target_size (tuple): Target size for resizing (width, height).\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_interval = int(video_fps / fps)\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process every nth frame based on the frame interval\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Resize frame\n",
    "            resized_frame = cv2.resize(frame, target_size)\n",
    "\n",
    "            # Save frame as a .jpg file\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "            saved_frame_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Processed {saved_frame_count} frames from {video_path} and saved to {output_folder}\")\n",
    "\n",
    "def process_all_videos(input_folder, output_folder, fps=2, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Process all videos in the input folder and save frames to the output folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input videos.\n",
    "        output_folder (str): Path to the folder to save processed frames.\n",
    "        fps (int): Frames per second to extract.\n",
    "        target_size (tuple): Target size for resizing (width, height).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for video_file in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, video_file)\n",
    "        video_output_folder = os.path.join(output_folder, os.path.splitext(video_file)[0])\n",
    "\n",
    "        if os.path.isfile(input_path) and video_file.endswith(\".mp4\"):\n",
    "            extract_and_process_frames(input_path, video_output_folder, fps, target_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input and output folders\n",
    "    base_path = \"F:/AIM Lab/Experiment/Clips\"\n",
    "    goal_input_folder = os.path.join(base_path, \"Goal p1\")\n",
    "    no_goal_input_folder = os.path.join(base_path, \"NoGoal p1\")\n",
    "    goal_output_folder = os.path.join(base_path, \"Goal p2\")\n",
    "    no_goal_output_folder = os.path.join(base_path, \"NoGoal p2\")\n",
    "\n",
    "    # Process videos in the \"Goal p1\" folder\n",
    "    print(\"Processing videos in the 'Goal p1' folder...\")\n",
    "    process_all_videos(goal_input_folder, goal_output_folder, fps=2, target_size=(224, 224))\n",
    "\n",
    "    # Process videos in the \"NoGoal p1\" folder\n",
    "    print(\"Processing videos in the 'NoGoal p1' folder...\")\n",
    "    process_all_videos(no_goal_input_folder, no_goal_output_folder, fps=2, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f6a30",
   "metadata": {},
   "source": [
    "### above cell was not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea14f9",
   "metadata": {},
   "source": [
    "### Using Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing goal clips:\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips/Goal p1/Test\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g31.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g31.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g31.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g31.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g32.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g32.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g32.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g32.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g33.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g33.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g33.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g33.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g34.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g34.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g34.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g34.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g35.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g35.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g35.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g35.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g36.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g36.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g36.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g36.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g37.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g37.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/Goal p1/Test\\g37.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\\g37.npy\n",
      "Processing non-goal clips:\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng31.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng31.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng31.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng31.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng32.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng32.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng32.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng32.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng33.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng33.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng33.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng33.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng34.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng34.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng34.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng34.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng35.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng35.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng35.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng35.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng36.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng36.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng36.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng36.npy\n",
      "Processing video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng37.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng37.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 16 frames from F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\\ng37.mp4\n",
      "Saved embedding to F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\\ng37.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from typing import List\n",
    "\n",
    "# Load ResNet-50 model\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # Remove the final classifier to get 2048-d features\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Preprocessing pipeline for frames\n",
    "preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),                    # H×W×C → C×H×W, [0,1]\n",
    "    torchvision.transforms.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225]),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "def embed_clip(frames: List[np.ndarray]):\n",
    "    \"\"\"\n",
    "    Generate ResNet-50 embeddings for a list of frames.\n",
    "    \n",
    "    Args:\n",
    "        frames (List[np.ndarray]): List of frames (H×W×C, BGR format).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: N×2048 array of frame embeddings.\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    for frame in frames:\n",
    "        # Convert BGR (OpenCV) to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        x = preprocess(frame_rgb).unsqueeze(0)  # 1×3×224×224\n",
    "        with torch.no_grad():\n",
    "            f = model(x)  # 1×2048\n",
    "        feats.append(f.squeeze(0).cpu().numpy())\n",
    "    return np.stack(feats, axis=0)  # N×2048\n",
    "\n",
    "def sample_frames_from_video(video_path, num_samples=16):\n",
    "    \"\"\"\n",
    "    Uniformly sample num_samples frames from the video at video_path.\n",
    "    Returns a list of BGR frames (as numpy arrays).\n",
    "    \"\"\"\n",
    "    print(f\"Opening video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "    if total_frames == 0:\n",
    "        print(f\"Error: No frames found in video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    if total_frames < num_samples:\n",
    "        # If fewer frames than samples, just read them all\n",
    "        indices = list(range(total_frames))\n",
    "    else:\n",
    "        # Uniformly spaced frame indices\n",
    "        indices = np.linspace(0, total_frames - 1, num=num_samples, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame {idx} from {video_path}\")\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(f\"Error: No frames sampled from video {video_path}\")\n",
    "    else:\n",
    "        print(f\"Successfully sampled {len(frames)} frames from {video_path}\")\n",
    "    return frames\n",
    "\n",
    "def process_folder(input_folder, output_folder, num_samples=16):\n",
    "    \"\"\"\n",
    "    Process videos in a folder, generate mean-pooled ResNet-50 embeddings for sampled frames,\n",
    "    and save the embeddings to the output folder.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input videos.\n",
    "        output_folder (str): Path to save embeddings.\n",
    "        num_samples (int): Number of frames to sample per video.\n",
    "    \"\"\"\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: Folder does not exist: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith('.mp4'):\n",
    "            print(f\"Skipping non-video file: {fname}\")\n",
    "            continue\n",
    "        video_path = os.path.join(input_folder, fname)\n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        frames = sample_frames_from_video(video_path, num_samples=num_samples)\n",
    "        if frames:\n",
    "            # Generate embeddings and mean-pool them\n",
    "            embeddings = embed_clip(frames)\n",
    "            clip_vec = np.mean(embeddings, axis=0)  # Mean-pool → (2048,)\n",
    "            \n",
    "            # Save the embedding as a .npy file\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}.npy\")\n",
    "            np.save(output_path, clip_vec)\n",
    "            print(f\"Saved embedding to {output_path}\")\n",
    "        else:\n",
    "            print(f\"Error: No frames sampled from {fname}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input and output folders\n",
    "    goal_folder = \"F:/AIM Lab/Experiment/Clips/Goal p1/Test\"\n",
    "    nongoal_folder = \"F:/AIM Lab/Experiment/Clips/NoGoal p1/Test\"\n",
    "    goal_output_folder = \"F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\"\n",
    "    nongoal_output_folder = \"F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\"\n",
    "\n",
    "    # Process goal clips\n",
    "    print(\"Processing goal clips:\")\n",
    "    process_folder(goal_folder, goal_output_folder, num_samples=16)\n",
    "\n",
    "    # Process non-goal clips\n",
    "    print(\"Processing non-goal clips:\")\n",
    "    process_folder(nongoal_folder, nongoal_output_folder, num_samples=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1a7b844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building prototypes...\n",
      "Classifying test clips...\n",
      "File: g31.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g32.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g33.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g34.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g35.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g36.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: g37.npy, True Label: Goal, Predicted Label: Goal\n",
      "File: ng31.npy, True Label: Non-Goal, Predicted Label: Non-Goal\n",
      "File: ng32.npy, True Label: Non-Goal, Predicted Label: Non-Goal\n",
      "File: ng33.npy, True Label: Non-Goal, Predicted Label: Non-Goal\n",
      "File: ng34.npy, True Label: Non-Goal, Predicted Label: Goal\n",
      "File: ng35.npy, True Label: Non-Goal, Predicted Label: Non-Goal\n",
      "File: ng36.npy, True Label: Non-Goal, Predicted Label: Goal\n",
      "File: ng37.npy, True Label: Non-Goal, Predicted Label: Non-Goal\n"
     ]
    }
   ],
   "source": [
    "def l2_normalize(vec):\n",
    "    \"\"\"\n",
    "    Perform L2 normalization on a vector.\n",
    "    \n",
    "    Args:\n",
    "        vec (np.ndarray): Input vector.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: L2-normalized vector.\n",
    "    \"\"\"\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "def build_prototypes(goal_folder, nongoal_folder):\n",
    "    \"\"\"\n",
    "    Build prototypes for goal and non-goal classes.\n",
    "    \n",
    "    Args:\n",
    "        goal_folder (str): Path to the folder containing goal clip embeddings.\n",
    "        nongoal_folder (str): Path to the folder containing non-goal clip embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: L2-normalized prototypes for goal and non-goal classes.\n",
    "    \"\"\"\n",
    "    goal_vecs = []\n",
    "    nongoal_vecs = []\n",
    "\n",
    "    # Load goal embeddings\n",
    "    for fname in os.listdir(goal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(goal_folder, fname))\n",
    "            goal_vecs.append(vec)\n",
    "\n",
    "    # Load non-goal embeddings\n",
    "    for fname in os.listdir(nongoal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(nongoal_folder, fname))\n",
    "            nongoal_vecs.append(vec)\n",
    "\n",
    "    # Compute mean vectors\n",
    "    proto_goal = np.mean(goal_vecs, axis=0)\n",
    "    proto_nongoal = np.mean(nongoal_vecs, axis=0)\n",
    "\n",
    "    # Normalize prototypes\n",
    "    proto_goal = l2_normalize(proto_goal)\n",
    "    proto_nongoal = l2_normalize(proto_nongoal)\n",
    "\n",
    "    return proto_goal, proto_nongoal\n",
    "\n",
    "def classify_clip(new_clip_vec, proto_goal, proto_nongoal, delta=0.04):\n",
    "    \"\"\"\n",
    "    Classify a new clip based on similarity to prototypes.\n",
    "    \n",
    "    Args:\n",
    "        new_clip_vec (np.ndarray): L2-normalized vector of the new clip.\n",
    "        proto_goal (np.ndarray): Prototype for the goal class.\n",
    "        proto_nongoal (np.ndarray): Prototype for the non-goal class.\n",
    "        delta (float): Decision threshold.\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted label (\"Goal\" or \"Non-Goal\").\n",
    "    \"\"\"\n",
    "    # Normalize the new clip vector\n",
    "    v = l2_normalize(new_clip_vec)\n",
    "\n",
    "    # Compute similarities\n",
    "    sim_goal = np.dot(v, proto_goal)\n",
    "    sim_nongoal = np.dot(v, proto_nongoal)\n",
    "\n",
    "    # Classify based on similarity\n",
    "    label = \"Goal\" if sim_goal > (sim_nongoal + delta) else \"Non-Goal\"\n",
    "    deltas = sim_goal - sim_nongoal\n",
    "    # print(\"difference: \", deltas)\n",
    "    # print(\"Sim_goal: \", sim_goal)\n",
    "    # print(\"sim_nongoal: \", sim_nongoal + delta)\n",
    "    return label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths to embedding folders\n",
    "    goal_train_folder = \"F:/AIM Lab/Experiment/Clips/Goal Embeddings/Train\"\n",
    "    nongoal_train_folder = \"F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Train\"\n",
    "    goal_test_folder = \"F:/AIM Lab/Experiment/Clips/Goal Embeddings/Test\"\n",
    "    nongoal_test_folder = \"F:/AIM Lab/Experiment/Clips/NoGoal Embeddings/Test\"\n",
    "\n",
    "    # Build prototypes\n",
    "    print(\"Building prototypes...\")\n",
    "    proto_goal, proto_nongoal = build_prototypes(goal_train_folder, nongoal_train_folder)\n",
    "\n",
    "    # Classify test clips\n",
    "    print(\"Classifying test clips...\")\n",
    "    for test_folder, label in [(goal_test_folder, \"Goal\"), (nongoal_test_folder, \"Non-Goal\")]:\n",
    "        for fname in os.listdir(test_folder):\n",
    "            if fname.endswith(\".npy\"):\n",
    "                # Load test clip vector\n",
    "                test_vec = np.load(os.path.join(test_folder, fname))\n",
    "\n",
    "                # Classify the clip\n",
    "                predicted_label = classify_clip(test_vec, proto_goal, proto_nongoal, 0.00)\n",
    "\n",
    "                # Print results\n",
    "                print(f\"File: {fname}, True Label: {label}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c05d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing goal clips...\n",
      "\n",
      "Testing non-goal clips...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 2]\n",
      " [0 7]]\n",
      "Precision: 0.7778\n",
      "Recall: 1.0000\n",
      "F₁ Score: 0.8750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "def classify_clip2(new_clip_vec, proto_goal, proto_nongoal, delta=0.04):\n",
    "    \"\"\"\n",
    "    Classify a new clip based on similarity to prototypes.\n",
    "    \"\"\"\n",
    "    # Normalize the new clip vector\n",
    "    v = l2_normalize(new_clip_vec)\n",
    "\n",
    "    # Compute similarities\n",
    "    sim_goal = np.dot(v, proto_goal)\n",
    "    sim_nongoal = np.dot(v, proto_nongoal)\n",
    "\n",
    "    # Classify based on similarity\n",
    "    label = \"Goal\" if sim_goal > (sim_nongoal + delta) else \"Non-Goal\"\n",
    "    similarity_scores = {\"sim_goal\": sim_goal, \"sim_nongoal\": sim_nongoal}\n",
    "\n",
    "    return label, similarity_scores\n",
    "\n",
    "def evaluate_classification_with_metrics(goal_test_folder: str, \n",
    "                                         nongoal_test_folder: str,\n",
    "                                         proto_goal: np.ndarray,\n",
    "                                         proto_nongoal: np.ndarray,\n",
    "                                         threshold: float = 0.0) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate classification performance and compute confusion matrix, precision, recall, and F₁ score.\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Test goal clips\n",
    "    print(\"\\nTesting goal clips...\")\n",
    "    for fname in os.listdir(goal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(goal_test_folder, fname))\n",
    "            predicted_label, _ = classify_clip2(test_embedding, proto_goal, proto_nongoal, threshold)\n",
    "            \n",
    "            y_true.append(1)  # True label: Goal\n",
    "            y_pred.append(1 if predicted_label == \"Goal\" else 0)\n",
    "    \n",
    "    # Test non-goal clips\n",
    "    print(\"\\nTesting non-goal clips...\")\n",
    "    for fname in os.listdir(nongoal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(nongoal_test_folder, fname))\n",
    "            predicted_label, _ = classify_clip2(test_embedding, proto_goal, proto_nongoal, threshold)\n",
    "            \n",
    "            y_true.append(0)  # True label: Non-Goal\n",
    "            y_pred.append(1 if predicted_label == \"Goal\" else 0)\n",
    "    \n",
    "    # Compute metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F₁ Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "\n",
    "results = evaluate_classification_with_metrics(\n",
    "    goal_test_folder=goal_test_folder, \n",
    "    nongoal_test_folder=nongoal_test_folder, \n",
    "    proto_goal=proto_goal, \n",
    "    proto_nongoal=proto_nongoal, \n",
    "    threshold=0.0  # Adjust the threshold as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6bc0eb",
   "metadata": {},
   "source": [
    "## Cossine Similarity-based classification Using I3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771954ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing I3D feature extractor...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "InceptionI3d.__init__() got an unexpected keyword argument 'in_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 532\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 484\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# Initialize I3D feature extractor\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing I3D feature extractor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 484\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mI3DFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# Step 1: Generate I3D embeddings for all videos\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStep 1: Generating I3D embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[43], line 25\u001b[0m, in \u001b[0;36mI3DFeatureExtractor.__init__\u001b[1;34m(self, model_path, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Initialize I3D model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mi3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInceptionI3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load pretrained weights if available\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sonnet\\src\\base.py:120\u001b[0m, in \u001b[0;36mModuleMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Now attempt to initialize the object.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m   module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m   exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "\u001b[1;31mTypeError\u001b[0m: InceptionI3d.__init__() got an unexpected keyword argument 'in_channels'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append(r'F:\\AIM Lab\\Experiment\\kinetics-i3d')\n",
    "import i3d\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "class I3DFeatureExtractor:\n",
    "    def __init__(self, model_path=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        \"\"\"\n",
    "        Initialize I3D model for feature extraction.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to pretrained I3D model (optional)\n",
    "            device: Device to run the model on\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize I3D model\n",
    "        self.model = i3d.InceptionI3d(400, in_channels=3)\n",
    "        \n",
    "        # Load pretrained weights if available\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "            self.model.load_state_dict(checkpoint)\n",
    "        \n",
    "        # Remove the final classification layer to get features\n",
    "        self.model.logits = torch.nn.Identity()\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Preprocessing transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def preprocess_frames(self, frames: List[np.ndarray], num_frames: int = 16) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess frames for I3D input.\n",
    "        \n",
    "        Args:\n",
    "            frames: List of frames (H×W×C, BGR format)\n",
    "            num_frames: Number of frames to use for I3D\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed tensor of shape (1, 3, num_frames, H, W)\n",
    "        \"\"\"\n",
    "        # Sample frames uniformly if we have more than needed\n",
    "        if len(frames) > num_frames:\n",
    "            indices = np.linspace(0, len(frames) - 1, num_frames, dtype=int)\n",
    "            frames = [frames[i] for i in indices]\n",
    "        elif len(frames) < num_frames:\n",
    "            # Repeat last frame if we don't have enough\n",
    "            while len(frames) < num_frames:\n",
    "                frames.append(frames[-1])\n",
    "        \n",
    "        # Convert frames and apply transforms\n",
    "        processed_frames = []\n",
    "        for frame in frames:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Apply transforms\n",
    "            frame_tensor = self.transform(frame_rgb)\n",
    "            processed_frames.append(frame_tensor)\n",
    "        \n",
    "        # Stack frames: (num_frames, 3, H, W) -> (3, num_frames, H, W)\n",
    "        video_tensor = torch.stack(processed_frames, dim=1)  # (3, num_frames, H, W)\n",
    "        video_tensor = video_tensor.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        return video_tensor\n",
    "    \n",
    "    def extract_features(self, frames: List[np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract I3D features from video frames.\n",
    "        \n",
    "        Args:\n",
    "            frames: List of video frames\n",
    "            \n",
    "        Returns:\n",
    "            Feature vector of shape (1024,) or similar\n",
    "        \"\"\"\n",
    "        # Preprocess frames\n",
    "        video_tensor = self.preprocess_frames(frames)\n",
    "        video_tensor = video_tensor.to(self.device)\n",
    "        \n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = self.model(video_tensor)\n",
    "            # Global average pooling if needed\n",
    "            if len(features.shape) > 2:\n",
    "                features = F.adaptive_avg_pool3d(features, 1).squeeze()\n",
    "            else:\n",
    "                features = features.squeeze()\n",
    "        \n",
    "        return features.cpu().numpy()\n",
    "\n",
    "def sample_frames_from_video(video_path: str, num_samples: int = 32) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Uniformly sample frames from a video.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        num_samples: Number of frames to sample\n",
    "        \n",
    "    Returns:\n",
    "        List of sampled frames\n",
    "    \"\"\"\n",
    "    print(f\"Opening video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "    \n",
    "    if total_frames == 0:\n",
    "        print(f\"Error: No frames found in video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    if total_frames < num_samples:\n",
    "        indices = list(range(total_frames))\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, num=num_samples, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame {idx} from {video_path}\")\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not frames:\n",
    "        print(f\"Error: No frames sampled from video {video_path}\")\n",
    "    else:\n",
    "        print(f\"Successfully sampled {len(frames)} frames from {video_path}\")\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def process_videos_to_i3d_embeddings(input_folder: str, output_folder: str, \n",
    "                                   feature_extractor: I3DFeatureExtractor,\n",
    "                                   num_frames: int = 32):\n",
    "    \"\"\"\n",
    "    Process all videos in a folder and generate I3D embeddings.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Folder containing input videos\n",
    "        output_folder: Folder to save embeddings\n",
    "        feature_extractor: I3D feature extractor instance\n",
    "        num_frames: Number of frames to use for each video\n",
    "    \"\"\"\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: Folder does not exist: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith('.mp4'):\n",
    "            print(f\"Skipping non-video file: {fname}\")\n",
    "            continue\n",
    "        \n",
    "        video_path = os.path.join(input_folder, fname)\n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        \n",
    "        # Sample frames from video\n",
    "        frames = sample_frames_from_video(video_path, num_samples=num_frames)\n",
    "        \n",
    "        if frames:\n",
    "            # Extract I3D features\n",
    "            try:\n",
    "                features = feature_extractor.extract_features(frames)\n",
    "                \n",
    "                # Save the embedding as a .npy file\n",
    "                output_path = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}.npy\")\n",
    "                np.save(output_path, features)\n",
    "                print(f\"Saved I3D embedding to {output_path} (shape: {features.shape})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {fname}: {e}\")\n",
    "        else:\n",
    "            print(f\"Error: No frames sampled from {fname}\")\n",
    "\n",
    "def l2_normalize(vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform L2 normalization on a vector.\n",
    "    \n",
    "    Args:\n",
    "        vec: Input vector\n",
    "        \n",
    "    Returns:\n",
    "        L2-normalized vector\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm == 0:\n",
    "        return vec\n",
    "    return vec / norm\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    \n",
    "    Args:\n",
    "        vec1: First vector\n",
    "        vec2: Second vector\n",
    "        \n",
    "    Returns:\n",
    "        Cosine similarity value\n",
    "    \"\"\"\n",
    "    # Normalize vectors\n",
    "    vec1_norm = l2_normalize(vec1)\n",
    "    vec2_norm = l2_normalize(vec2)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return np.dot(vec1_norm, vec2_norm)\n",
    "\n",
    "def build_i3d_prototypes(goal_folder: str, nongoal_folder: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build prototypes for goal and non-goal classes using I3D embeddings.\n",
    "    \n",
    "    Args:\n",
    "        goal_folder: Path to folder containing goal clip embeddings\n",
    "        nongoal_folder: Path to folder containing non-goal clip embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (goal_prototype, nongoal_prototype)\n",
    "    \"\"\"\n",
    "    goal_vecs = []\n",
    "    nongoal_vecs = []\n",
    "\n",
    "    # Load goal embeddings\n",
    "    print(\"Loading goal embeddings...\")\n",
    "    for fname in os.listdir(goal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(goal_folder, fname))\n",
    "            goal_vecs.append(vec)\n",
    "            print(f\"Loaded goal embedding: {fname} (shape: {vec.shape})\")\n",
    "\n",
    "    # Load non-goal embeddings\n",
    "    print(\"Loading non-goal embeddings...\")\n",
    "    for fname in os.listdir(nongoal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(nongoal_folder, fname))\n",
    "            nongoal_vecs.append(vec)\n",
    "            print(f\"Loaded non-goal embedding: {fname} (shape: {vec.shape})\")\n",
    "\n",
    "    if not goal_vecs or not nongoal_vecs:\n",
    "        raise ValueError(\"No embeddings found in one or both folders!\")\n",
    "\n",
    "    # Compute mean vectors (prototypes)\n",
    "    proto_goal = np.mean(goal_vecs, axis=0)\n",
    "    proto_nongoal = np.mean(nongoal_vecs, axis=0)\n",
    "\n",
    "    # Normalize prototypes\n",
    "    proto_goal = l2_normalize(proto_goal)\n",
    "    proto_nongoal = l2_normalize(proto_nongoal)\n",
    "\n",
    "    print(f\"Goal prototype shape: {proto_goal.shape}\")\n",
    "    print(f\"Non-goal prototype shape: {proto_nongoal.shape}\")\n",
    "    print(f\"Built prototypes from {len(goal_vecs)} goal and {len(nongoal_vecs)} non-goal samples\")\n",
    "\n",
    "    return proto_goal, proto_nongoal\n",
    "\n",
    "def classify_i3d_clip(clip_embedding: np.ndarray, \n",
    "                     proto_goal: np.ndarray, \n",
    "                     proto_nongoal: np.ndarray, \n",
    "                     threshold: float = 0.0) -> Tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Classify a clip using cosine similarity to prototypes.\n",
    "    \n",
    "    Args:\n",
    "        clip_embedding: I3D embedding of the clip to classify\n",
    "        proto_goal: Goal class prototype\n",
    "        proto_nongoal: Non-goal class prototype\n",
    "        threshold: Decision threshold\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (predicted_label, similarity_scores)\n",
    "    \"\"\"\n",
    "    # Normalize the clip embedding\n",
    "    clip_norm = l2_normalize(clip_embedding)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    sim_goal = cosine_similarity(clip_norm, proto_goal)\n",
    "    sim_nongoal = cosine_similarity(clip_norm, proto_nongoal)\n",
    "\n",
    "    # Classify based on similarity difference and threshold\n",
    "    difference = sim_goal - sim_nongoal\n",
    "    predicted_label = \"Goal\" if difference > threshold else \"Non-Goal\"\n",
    "    \n",
    "    similarity_scores = {\n",
    "        'sim_goal': sim_goal,\n",
    "        'sim_nongoal': sim_nongoal,\n",
    "        'difference': difference,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "    return predicted_label, similarity_scores\n",
    "\n",
    "def evaluate_i3d_classification(goal_test_folder: str, \n",
    "                               nongoal_test_folder: str,\n",
    "                               proto_goal: np.ndarray,\n",
    "                               proto_nongoal: np.ndarray,\n",
    "                               threshold: float = 0.0) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate I3D-based classification on test data.\n",
    "    \n",
    "    Args:\n",
    "        goal_test_folder: Folder containing goal test embeddings\n",
    "        nongoal_test_folder: Folder containing non-goal test embeddings\n",
    "        proto_goal: Goal class prototype\n",
    "        proto_nongoal: Non-goal class prototype\n",
    "        threshold: Decision threshold\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing evaluation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'correct': 0,\n",
    "        'total': 0,\n",
    "        'goal_correct': 0,\n",
    "        'goal_total': 0,\n",
    "        'nongoal_correct': 0,\n",
    "        'nongoal_total': 0,\n",
    "        'predictions': []\n",
    "    }\n",
    "    \n",
    "    # Test goal clips\n",
    "    print(\"\\nTesting goal clips...\")\n",
    "    for fname in os.listdir(goal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(goal_test_folder, fname))\n",
    "            predicted_label, sim_scores = classify_i3d_clip(\n",
    "                test_embedding, proto_goal, proto_nongoal, threshold\n",
    "            )\n",
    "            \n",
    "            is_correct = predicted_label == \"Goal\"\n",
    "            results['goal_total'] += 1\n",
    "            results['total'] += 1\n",
    "            \n",
    "            if is_correct:\n",
    "                results['goal_correct'] += 1\n",
    "                results['correct'] += 1\n",
    "            \n",
    "            result_entry = {\n",
    "                'file': fname,\n",
    "                'true_label': 'Goal',\n",
    "                'predicted_label': predicted_label,\n",
    "                'correct': is_correct,\n",
    "                'similarities': sim_scores\n",
    "            }\n",
    "            results['predictions'].append(result_entry)\n",
    "            \n",
    "            print(f\"File: {fname}\")\n",
    "            print(f\"  True: Goal, Predicted: {predicted_label}\")\n",
    "            print(f\"  Sim Goal: {sim_scores['sim_goal']:.4f}, Sim Non-Goal: {sim_scores['sim_nongoal']:.4f}\")\n",
    "            print(f\"  Difference: {sim_scores['difference']:.4f}, Correct: {is_correct}\")\n",
    "    \n",
    "    # Test non-goal clips\n",
    "    print(\"\\nTesting non-goal clips...\")\n",
    "    for fname in os.listdir(nongoal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(nongoal_test_folder, fname))\n",
    "            predicted_label, sim_scores = classify_i3d_clip(\n",
    "                test_embedding, proto_goal, proto_nongoal, threshold\n",
    "            )\n",
    "            \n",
    "            is_correct = predicted_label == \"Non-Goal\"\n",
    "            results['nongoal_total'] += 1\n",
    "            results['total'] += 1\n",
    "            \n",
    "            if is_correct:\n",
    "                results['nongoal_correct'] += 1\n",
    "                results['correct'] += 1\n",
    "            \n",
    "            result_entry = {\n",
    "                'file': fname,\n",
    "                'true_label': 'Non-Goal',\n",
    "                'predicted_label': predicted_label,\n",
    "                'correct': is_correct,\n",
    "                'similarities': sim_scores\n",
    "            }\n",
    "            results['predictions'].append(result_entry)\n",
    "            \n",
    "            print(f\"File: {fname}\")\n",
    "            print(f\"  True: Non-Goal, Predicted: {predicted_label}\")\n",
    "            print(f\"  Sim Goal: {sim_scores['sim_goal']:.4f}, Sim Non-Goal: {sim_scores['sim_nongoal']:.4f}\")\n",
    "            print(f\"  Difference: {sim_scores['difference']:.4f}, Correct: {is_correct}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    overall_accuracy = results['correct'] / results['total'] if results['total'] > 0 else 0\n",
    "    goal_accuracy = results['goal_correct'] / results['goal_total'] if results['goal_total'] > 0 else 0\n",
    "    nongoal_accuracy = results['nongoal_correct'] / results['nongoal_total'] if results['nongoal_total'] > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({results['correct']}/{results['total']})\")\n",
    "    print(f\"Goal Accuracy: {goal_accuracy:.4f} ({results['goal_correct']}/{results['goal_total']})\")\n",
    "    print(f\"Non-Goal Accuracy: {nongoal_accuracy:.4f} ({results['nongoal_correct']}/{results['nongoal_total']})\")\n",
    "    \n",
    "    results['overall_accuracy'] = overall_accuracy\n",
    "    results['goal_accuracy'] = goal_accuracy\n",
    "    results['nongoal_accuracy'] = nongoal_accuracy\n",
    "    \n",
    "    return results\n",
    "\n",
    "def split_embeddings_train_test(input_folder: str, train_folder: str, test_folder: str, \n",
    "                               train_ratio: float = 0.7):\n",
    "    \"\"\"\n",
    "    Split embeddings into train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Folder containing all embeddings\n",
    "        train_folder: Output folder for training embeddings\n",
    "        test_folder: Output folder for test embeddings\n",
    "        train_ratio: Ratio of data to use for training\n",
    "    \"\"\"\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all .npy files\n",
    "    embedding_files = [f for f in os.listdir(input_folder) if f.endswith('.npy')]\n",
    "    random.shuffle(embedding_files)\n",
    "    \n",
    "    # Split files\n",
    "    split_idx = int(len(embedding_files) * train_ratio)\n",
    "    train_files = embedding_files[:split_idx]\n",
    "    test_files = embedding_files[split_idx:]\n",
    "    \n",
    "    # Copy files to respective folders\n",
    "    import shutil\n",
    "    \n",
    "    for file in train_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(train_folder, file)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    for file in test_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(test_folder, file)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    print(f\"Split {len(embedding_files)} files: {len(train_files)} train, {len(test_files)} test\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run I3D-based few-shot learning classification.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    base_path = \"F:/AIM Lab/Experiment/Clips\"\n",
    "    \n",
    "    # Input video folders\n",
    "    goal_video_folder = os.path.join(base_path, \"Goal p1\")\n",
    "    nongoal_video_folder = os.path.join(base_path, \"NoGoal p1\")\n",
    "    \n",
    "    # I3D embedding folders\n",
    "    i3d_base_path = os.path.join(base_path, \"I3D_Embeddings\")\n",
    "    goal_i3d_folder = os.path.join(i3d_base_path, \"Goal\")\n",
    "    nongoal_i3d_folder = os.path.join(i3d_base_path, \"NoGoal\")\n",
    "    \n",
    "    # Train/test split folders\n",
    "    goal_train_folder = os.path.join(i3d_base_path, \"Goal_Train\")\n",
    "    goal_test_folder = os.path.join(i3d_base_path, \"Goal_Test\")\n",
    "    nongoal_train_folder = os.path.join(i3d_base_path, \"NoGoal_Train\")\n",
    "    nongoal_test_folder = os.path.join(i3d_base_path, \"NoGoal_Test\")\n",
    "    \n",
    "    # Initialize I3D feature extractor\n",
    "    print(\"Initializing I3D feature extractor...\")\n",
    "    feature_extractor = I3DFeatureExtractor()\n",
    "    \n",
    "    # Step 1: Generate I3D embeddings for all videos\n",
    "    print(\"\\nStep 1: Generating I3D embeddings...\")\n",
    "    print(\"Processing goal videos...\")\n",
    "    process_videos_to_i3d_embeddings(goal_video_folder, goal_i3d_folder, feature_extractor)\n",
    "    \n",
    "    print(\"Processing non-goal videos...\")\n",
    "    process_videos_to_i3d_embeddings(nongoal_video_folder, nongoal_i3d_folder, feature_extractor)\n",
    "    \n",
    "    # Step 2: Split embeddings into train/test sets\n",
    "    print(\"\\nStep 2: Splitting embeddings into train/test sets...\")\n",
    "    split_embeddings_train_test(goal_i3d_folder, goal_train_folder, goal_test_folder, train_ratio=0.7)\n",
    "    split_embeddings_train_test(nongoal_i3d_folder, nongoal_train_folder, nongoal_test_folder, train_ratio=0.7)\n",
    "    \n",
    "    # Step 3: Build prototypes from training data\n",
    "    print(\"\\nStep 3: Building prototypes from training data...\")\n",
    "    try:\n",
    "        proto_goal, proto_nongoal = build_i3d_prototypes(goal_train_folder, nongoal_train_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error building prototypes: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Evaluate on test data with different thresholds\n",
    "    print(\"\\nStep 4: Evaluating classification performance...\")\n",
    "    thresholds = [0.0, 0.01, 0.02, 0.05, 0.1]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_threshold = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nTesting with threshold: {threshold}\")\n",
    "        results = evaluate_i3d_classification(\n",
    "            goal_test_folder, nongoal_test_folder, \n",
    "            proto_goal, proto_nongoal, threshold\n",
    "        )\n",
    "        \n",
    "        if results['overall_accuracy'] > best_accuracy:\n",
    "            best_accuracy = results['overall_accuracy']\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"BEST RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Best Threshold: {best_threshold}\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f981b",
   "metadata": {},
   "source": [
    "## Cossine Similarity-based classification Using R(2+1)D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5df5b321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing R(2+1)D feature extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R2Plus1D_18_Weights.KINETICS400_V1`. You can also use `weights=R2Plus1D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Generating R(2+1)D embeddings...\n",
      "Processing goal training videos...\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g1.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g1.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g1.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g1.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g10.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g10.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g10.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g10.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g11.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g11.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g11.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g11.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g12.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g12.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g12.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g12.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g13.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g13.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g13.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g13.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g14.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g14.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g14.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g14.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g15.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g15.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g15.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g15.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g16.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g16.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g16.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g16.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g17.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g17.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g17.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g17.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g18.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g18.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g18.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g18.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g19.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g19.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g19.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g19.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g2.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g2.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g2.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g2.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g20.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g20.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g20.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g20.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g21.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g21.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g21.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g21.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g22.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g22.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g22.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g22.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g23.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g23.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g23.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g23.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g24.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g24.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g24.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g24.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g25.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g25.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g25.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g25.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g26.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g26.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g26.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g26.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g27.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g27.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g27.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g27.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g28.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g28.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g28.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g28.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g29.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g29.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g29.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g29.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g3.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g3.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g3.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g3.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g30.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g30.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g30.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g30.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g4.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g4.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g4.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g4.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g5.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g5.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g5.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g5.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g6.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g6.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g6.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g6.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g7.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g7.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g7.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g7.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g8.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g8.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g8.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g8.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g9.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g9.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Train\\g9.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Train\\g9.npy (shape: (512,))\n",
      "Processing goal test videos...\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g31.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g31.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g31.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g31.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g32.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g32.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g32.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g32.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g33.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g33.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g33.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g33.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g34.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g34.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g34.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g34.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g35.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g35.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g35.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g35.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g36.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g36.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g36.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g36.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g37.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g37.mp4\n",
      "Total frames in video: 175\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\Goal p1\\Test\\g37.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\Goal_Test\\g37.npy (shape: (512,))\n",
      "Processing non-goal training videos...\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng1.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng1.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng1.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng1.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng10.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng10.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng10.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng10.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng11.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng11.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng11.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng11.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng12.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng12.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng12.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng12.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng13.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng13.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng13.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng13.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng14.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng14.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng14.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng14.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng15.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng15.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng15.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng15.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng16.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng16.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng16.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng16.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng17.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng17.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng17.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng17.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng18.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng18.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng18.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng18.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng19.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng19.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng19.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng19.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng2.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng2.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng2.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng2.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng20.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng20.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng20.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng20.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng21.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng21.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng21.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng21.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng22.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng22.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng22.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng22.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng23.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng23.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng23.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng23.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng24.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng24.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng24.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng24.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng25.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng25.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng25.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng25.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng26.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng26.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng26.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng26.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng27.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng27.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng27.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng27.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng28.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng28.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng28.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng28.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng29.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng29.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng29.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng29.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng3.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng3.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng3.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng3.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng30.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng30.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng30.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng30.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng4.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng4.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng4.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng4.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng5.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng5.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng5.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng5.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng6.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng6.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng6.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng6.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng7.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng7.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng7.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng7.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng8.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng8.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng8.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng8.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng9.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng9.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Train\\ng9.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Train\\ng9.npy (shape: (512,))\n",
      "Processing non-goal test videos...\n",
      "Processing folder: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng31.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng31.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng31.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng31.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng32.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng32.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng32.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng32.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng33.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng33.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng33.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng33.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng34.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng34.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng34.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng34.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng35.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng35.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng35.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng35.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng36.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng36.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng36.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng36.npy (shape: (512,))\n",
      "Processing video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng37.mp4\n",
      "Opening video: F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng37.mp4\n",
      "Total frames in video: 150\n",
      "Successfully sampled 32 frames from F:/AIM Lab/Experiment/Clips\\NoGoal p1\\Test\\ng37.mp4\n",
      "Saved R(2+1)D embedding to F:/AIM Lab/Experiment/Clips\\R2Plus1D_Embeddings\\NoGoal_Test\\ng37.npy (shape: (512,))\n",
      "\n",
      "Step 2: Building prototypes from training data...\n",
      "Loading goal embeddings...\n",
      "Loaded goal embedding: g1.npy (shape: (512,))\n",
      "Loaded goal embedding: g10.npy (shape: (512,))\n",
      "Loaded goal embedding: g11.npy (shape: (512,))\n",
      "Loaded goal embedding: g12.npy (shape: (512,))\n",
      "Loaded goal embedding: g13.npy (shape: (512,))\n",
      "Loaded goal embedding: g14.npy (shape: (512,))\n",
      "Loaded goal embedding: g15.npy (shape: (512,))\n",
      "Loaded goal embedding: g16.npy (shape: (512,))\n",
      "Loaded goal embedding: g17.npy (shape: (512,))\n",
      "Loaded goal embedding: g18.npy (shape: (512,))\n",
      "Loaded goal embedding: g19.npy (shape: (512,))\n",
      "Loaded goal embedding: g2.npy (shape: (512,))\n",
      "Loaded goal embedding: g20.npy (shape: (512,))\n",
      "Loaded goal embedding: g21.npy (shape: (512,))\n",
      "Loaded goal embedding: g22.npy (shape: (512,))\n",
      "Loaded goal embedding: g23.npy (shape: (512,))\n",
      "Loaded goal embedding: g24.npy (shape: (512,))\n",
      "Loaded goal embedding: g25.npy (shape: (512,))\n",
      "Loaded goal embedding: g26.npy (shape: (512,))\n",
      "Loaded goal embedding: g27.npy (shape: (512,))\n",
      "Loaded goal embedding: g28.npy (shape: (512,))\n",
      "Loaded goal embedding: g29.npy (shape: (512,))\n",
      "Loaded goal embedding: g3.npy (shape: (512,))\n",
      "Loaded goal embedding: g30.npy (shape: (512,))\n",
      "Loaded goal embedding: g4.npy (shape: (512,))\n",
      "Loaded goal embedding: g5.npy (shape: (512,))\n",
      "Loaded goal embedding: g6.npy (shape: (512,))\n",
      "Loaded goal embedding: g7.npy (shape: (512,))\n",
      "Loaded goal embedding: g8.npy (shape: (512,))\n",
      "Loaded goal embedding: g9.npy (shape: (512,))\n",
      "Loading non-goal embeddings...\n",
      "Loaded non-goal embedding: ng1.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng10.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng11.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng12.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng13.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng14.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng15.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng16.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng17.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng18.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng19.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng2.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng20.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng21.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng22.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng23.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng24.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng25.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng26.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng27.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng28.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng29.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng3.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng30.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng4.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng5.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng6.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng7.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng8.npy (shape: (512,))\n",
      "Loaded non-goal embedding: ng9.npy (shape: (512,))\n",
      "Goal prototype shape: (512,)\n",
      "Non-goal prototype shape: (512,)\n",
      "Built prototypes from 30 goal and 30 non-goal samples\n",
      "\n",
      "Step 3: Evaluating classification performance...\n",
      "\n",
      "Testing with threshold: 0.0\n",
      "\n",
      "Testing goal clips...\n",
      "File: g31.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9084, Sim Non-Goal: 0.8992\n",
      "  Difference: 0.0092, Correct: True\n",
      "File: g32.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9081, Sim Non-Goal: 0.8810\n",
      "  Difference: 0.0271, Correct: True\n",
      "File: g33.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8963, Sim Non-Goal: 0.8623\n",
      "  Difference: 0.0340, Correct: True\n",
      "File: g34.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9176, Sim Non-Goal: 0.8940\n",
      "  Difference: 0.0235, Correct: True\n",
      "File: g35.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9260, Sim Non-Goal: 0.9181\n",
      "  Difference: 0.0079, Correct: True\n",
      "File: g36.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9090, Sim Non-Goal: 0.8988\n",
      "  Difference: 0.0102, Correct: True\n",
      "File: g37.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8989, Sim Non-Goal: 0.8799\n",
      "  Difference: 0.0190, Correct: True\n",
      "\n",
      "Testing non-goal clips...\n",
      "File: ng31.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8693, Sim Non-Goal: 0.9094\n",
      "  Difference: -0.0401, Correct: True\n",
      "File: ng32.npy\n",
      "  True: Non-Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8785, Sim Non-Goal: 0.8498\n",
      "  Difference: 0.0287, Correct: False\n",
      "File: ng33.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9054, Sim Non-Goal: 0.9225\n",
      "  Difference: -0.0171, Correct: True\n",
      "File: ng34.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8937, Sim Non-Goal: 0.9218\n",
      "  Difference: -0.0281, Correct: True\n",
      "File: ng35.npy\n",
      "  True: Non-Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8742, Sim Non-Goal: 0.8726\n",
      "  Difference: 0.0015, Correct: False\n",
      "File: ng36.npy\n",
      "  True: Non-Goal, Predicted: Goal\n",
      "  Sim Goal: 0.7916, Sim Non-Goal: 0.7884\n",
      "  Difference: 0.0032, Correct: False\n",
      "File: ng37.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8728, Sim Non-Goal: 0.8749\n",
      "  Difference: -0.0021, Correct: True\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.7857 (11/14)\n",
      "Goal Accuracy: 1.0000 (7/7)\n",
      "Non-Goal Accuracy: 0.5714 (4/7)\n",
      "\n",
      "Testing with threshold: 0.01\n",
      "\n",
      "Testing goal clips...\n",
      "File: g31.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9084, Sim Non-Goal: 0.8992\n",
      "  Difference: 0.0092, Correct: False\n",
      "File: g32.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9081, Sim Non-Goal: 0.8810\n",
      "  Difference: 0.0271, Correct: True\n",
      "File: g33.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8963, Sim Non-Goal: 0.8623\n",
      "  Difference: 0.0340, Correct: True\n",
      "File: g34.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9176, Sim Non-Goal: 0.8940\n",
      "  Difference: 0.0235, Correct: True\n",
      "File: g35.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9260, Sim Non-Goal: 0.9181\n",
      "  Difference: 0.0079, Correct: False\n",
      "File: g36.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9090, Sim Non-Goal: 0.8988\n",
      "  Difference: 0.0102, Correct: True\n",
      "File: g37.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8989, Sim Non-Goal: 0.8799\n",
      "  Difference: 0.0190, Correct: True\n",
      "\n",
      "Testing non-goal clips...\n",
      "File: ng31.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8693, Sim Non-Goal: 0.9094\n",
      "  Difference: -0.0401, Correct: True\n",
      "File: ng32.npy\n",
      "  True: Non-Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8785, Sim Non-Goal: 0.8498\n",
      "  Difference: 0.0287, Correct: False\n",
      "File: ng33.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9054, Sim Non-Goal: 0.9225\n",
      "  Difference: -0.0171, Correct: True\n",
      "File: ng34.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8937, Sim Non-Goal: 0.9218\n",
      "  Difference: -0.0281, Correct: True\n",
      "File: ng35.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8742, Sim Non-Goal: 0.8726\n",
      "  Difference: 0.0015, Correct: True\n",
      "File: ng36.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.7916, Sim Non-Goal: 0.7884\n",
      "  Difference: 0.0032, Correct: True\n",
      "File: ng37.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8728, Sim Non-Goal: 0.8749\n",
      "  Difference: -0.0021, Correct: True\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.7857 (11/14)\n",
      "Goal Accuracy: 0.7143 (5/7)\n",
      "Non-Goal Accuracy: 0.8571 (6/7)\n",
      "\n",
      "Testing with threshold: 0.02\n",
      "\n",
      "Testing goal clips...\n",
      "File: g31.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9084, Sim Non-Goal: 0.8992\n",
      "  Difference: 0.0092, Correct: False\n",
      "File: g32.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9081, Sim Non-Goal: 0.8810\n",
      "  Difference: 0.0271, Correct: True\n",
      "File: g33.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8963, Sim Non-Goal: 0.8623\n",
      "  Difference: 0.0340, Correct: True\n",
      "File: g34.npy\n",
      "  True: Goal, Predicted: Goal\n",
      "  Sim Goal: 0.9176, Sim Non-Goal: 0.8940\n",
      "  Difference: 0.0235, Correct: True\n",
      "File: g35.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9260, Sim Non-Goal: 0.9181\n",
      "  Difference: 0.0079, Correct: False\n",
      "File: g36.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9090, Sim Non-Goal: 0.8988\n",
      "  Difference: 0.0102, Correct: False\n",
      "File: g37.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8989, Sim Non-Goal: 0.8799\n",
      "  Difference: 0.0190, Correct: False\n",
      "\n",
      "Testing non-goal clips...\n",
      "File: ng31.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8693, Sim Non-Goal: 0.9094\n",
      "  Difference: -0.0401, Correct: True\n",
      "File: ng32.npy\n",
      "  True: Non-Goal, Predicted: Goal\n",
      "  Sim Goal: 0.8785, Sim Non-Goal: 0.8498\n",
      "  Difference: 0.0287, Correct: False\n",
      "File: ng33.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9054, Sim Non-Goal: 0.9225\n",
      "  Difference: -0.0171, Correct: True\n",
      "File: ng34.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8937, Sim Non-Goal: 0.9218\n",
      "  Difference: -0.0281, Correct: True\n",
      "File: ng35.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8742, Sim Non-Goal: 0.8726\n",
      "  Difference: 0.0015, Correct: True\n",
      "File: ng36.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.7916, Sim Non-Goal: 0.7884\n",
      "  Difference: 0.0032, Correct: True\n",
      "File: ng37.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8728, Sim Non-Goal: 0.8749\n",
      "  Difference: -0.0021, Correct: True\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.6429 (9/14)\n",
      "Goal Accuracy: 0.4286 (3/7)\n",
      "Non-Goal Accuracy: 0.8571 (6/7)\n",
      "\n",
      "Testing with threshold: 0.05\n",
      "\n",
      "Testing goal clips...\n",
      "File: g31.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9084, Sim Non-Goal: 0.8992\n",
      "  Difference: 0.0092, Correct: False\n",
      "File: g32.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9081, Sim Non-Goal: 0.8810\n",
      "  Difference: 0.0271, Correct: False\n",
      "File: g33.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8963, Sim Non-Goal: 0.8623\n",
      "  Difference: 0.0340, Correct: False\n",
      "File: g34.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9176, Sim Non-Goal: 0.8940\n",
      "  Difference: 0.0235, Correct: False\n",
      "File: g35.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9260, Sim Non-Goal: 0.9181\n",
      "  Difference: 0.0079, Correct: False\n",
      "File: g36.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9090, Sim Non-Goal: 0.8988\n",
      "  Difference: 0.0102, Correct: False\n",
      "File: g37.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8989, Sim Non-Goal: 0.8799\n",
      "  Difference: 0.0190, Correct: False\n",
      "\n",
      "Testing non-goal clips...\n",
      "File: ng31.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8693, Sim Non-Goal: 0.9094\n",
      "  Difference: -0.0401, Correct: True\n",
      "File: ng32.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8785, Sim Non-Goal: 0.8498\n",
      "  Difference: 0.0287, Correct: True\n",
      "File: ng33.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9054, Sim Non-Goal: 0.9225\n",
      "  Difference: -0.0171, Correct: True\n",
      "File: ng34.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8937, Sim Non-Goal: 0.9218\n",
      "  Difference: -0.0281, Correct: True\n",
      "File: ng35.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8742, Sim Non-Goal: 0.8726\n",
      "  Difference: 0.0015, Correct: True\n",
      "File: ng36.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.7916, Sim Non-Goal: 0.7884\n",
      "  Difference: 0.0032, Correct: True\n",
      "File: ng37.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8728, Sim Non-Goal: 0.8749\n",
      "  Difference: -0.0021, Correct: True\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.5000 (7/14)\n",
      "Goal Accuracy: 0.0000 (0/7)\n",
      "Non-Goal Accuracy: 1.0000 (7/7)\n",
      "\n",
      "Testing with threshold: 0.1\n",
      "\n",
      "Testing goal clips...\n",
      "File: g31.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9084, Sim Non-Goal: 0.8992\n",
      "  Difference: 0.0092, Correct: False\n",
      "File: g32.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9081, Sim Non-Goal: 0.8810\n",
      "  Difference: 0.0271, Correct: False\n",
      "File: g33.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8963, Sim Non-Goal: 0.8623\n",
      "  Difference: 0.0340, Correct: False\n",
      "File: g34.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9176, Sim Non-Goal: 0.8940\n",
      "  Difference: 0.0235, Correct: False\n",
      "File: g35.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9260, Sim Non-Goal: 0.9181\n",
      "  Difference: 0.0079, Correct: False\n",
      "File: g36.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9090, Sim Non-Goal: 0.8988\n",
      "  Difference: 0.0102, Correct: False\n",
      "File: g37.npy\n",
      "  True: Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8989, Sim Non-Goal: 0.8799\n",
      "  Difference: 0.0190, Correct: False\n",
      "\n",
      "Testing non-goal clips...\n",
      "File: ng31.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8693, Sim Non-Goal: 0.9094\n",
      "  Difference: -0.0401, Correct: True\n",
      "File: ng32.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8785, Sim Non-Goal: 0.8498\n",
      "  Difference: 0.0287, Correct: True\n",
      "File: ng33.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.9054, Sim Non-Goal: 0.9225\n",
      "  Difference: -0.0171, Correct: True\n",
      "File: ng34.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8937, Sim Non-Goal: 0.9218\n",
      "  Difference: -0.0281, Correct: True\n",
      "File: ng35.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8742, Sim Non-Goal: 0.8726\n",
      "  Difference: 0.0015, Correct: True\n",
      "File: ng36.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.7916, Sim Non-Goal: 0.7884\n",
      "  Difference: 0.0032, Correct: True\n",
      "File: ng37.npy\n",
      "  True: Non-Goal, Predicted: Non-Goal\n",
      "  Sim Goal: 0.8728, Sim Non-Goal: 0.8749\n",
      "  Difference: -0.0021, Correct: True\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.5000 (7/14)\n",
      "Goal Accuracy: 0.0000 (0/7)\n",
      "Non-Goal Accuracy: 1.0000 (7/7)\n",
      "\n",
      "Step 4: Detailed evaluation with best threshold (0.0)...\n",
      "\n",
      "Testing goal clips...\n",
      "Testing non-goal clips...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 3]\n",
      " [0 7]]\n",
      "Precision: 0.7000\n",
      "Recall: 1.0000\n",
      "F₁ Score: 0.8235\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS\n",
      "==================================================\n",
      "Best Threshold: 0.0\n",
      "Best Accuracy: 0.7857\n",
      "Precision: 0.7000\n",
      "Recall: 1.0000\n",
      "F₁ Score: 0.8235\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "class R2Plus1DFeatureExtractor:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        \"\"\"\n",
    "        Initialize R(2+1)D model for feature extraction.\n",
    "        \n",
    "        Args:\n",
    "            device: Device to run the model on\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize R(2+1)D model\n",
    "        self.model = r2plus1d_18(pretrained=True)\n",
    "        \n",
    "        # Remove the final classification layer to get features\n",
    "        self.model.fc = torch.nn.Identity()\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Preprocessing transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((112, 112)),  # R(2+1)D typically uses 112x112\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], \n",
    "                               std=[0.22803, 0.22145, 0.216989])  # Kinetics normalization\n",
    "        ])\n",
    "    \n",
    "    def preprocess_frames(self, frames: List[np.ndarray], num_frames: int = 16) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess frames for R(2+1)D input.\n",
    "        \n",
    "        Args:\n",
    "            frames: List of frames (H×W×C, BGR format)\n",
    "            num_frames: Number of frames to use for R(2+1)D\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed tensor of shape (1, 3, num_frames, H, W)\n",
    "        \"\"\"\n",
    "        # Sample frames uniformly if we have more than needed\n",
    "        if len(frames) > num_frames:\n",
    "            indices = np.linspace(0, len(frames) - 1, num_frames, dtype=int)\n",
    "            frames = [frames[i] for i in indices]\n",
    "        elif len(frames) < num_frames:\n",
    "            # Repeat last frame if we don't have enough\n",
    "            while len(frames) < num_frames:\n",
    "                frames.append(frames[-1])\n",
    "        \n",
    "        # Convert frames and apply transforms\n",
    "        processed_frames = []\n",
    "        for frame in frames:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Apply transforms\n",
    "            frame_tensor = self.transform(frame_rgb)\n",
    "            processed_frames.append(frame_tensor)\n",
    "        \n",
    "        # Stack frames: (num_frames, 3, H, W) -> (3, num_frames, H, W)\n",
    "        video_tensor = torch.stack(processed_frames, dim=1)  # (3, num_frames, H, W)\n",
    "        video_tensor = video_tensor.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        return video_tensor\n",
    "    \n",
    "    def extract_features(self, frames: List[np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract R(2+1)D features from video frames.\n",
    "        \n",
    "        Args:\n",
    "            frames: List of video frames\n",
    "            \n",
    "        Returns:\n",
    "            Feature vector of shape (512,) for R(2+1)D-18\n",
    "        \"\"\"\n",
    "        # Preprocess frames\n",
    "        video_tensor = self.preprocess_frames(frames)\n",
    "        video_tensor = video_tensor.to(self.device)\n",
    "        \n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = self.model(video_tensor)\n",
    "            # Global average pooling if needed\n",
    "            if len(features.shape) > 2:\n",
    "                features = F.adaptive_avg_pool3d(features, 1).squeeze()\n",
    "            else:\n",
    "                features = features.squeeze()\n",
    "        \n",
    "        return features.cpu().numpy()\n",
    "\n",
    "def sample_frames_from_video(video_path: str, num_samples: int = 32) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Uniformly sample frames from a video.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        num_samples: Number of frames to sample\n",
    "        \n",
    "    Returns:\n",
    "        List of sampled frames\n",
    "    \"\"\"\n",
    "    print(f\"Opening video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "    \n",
    "    if total_frames == 0:\n",
    "        print(f\"Error: No frames found in video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    if total_frames < num_samples:\n",
    "        indices = list(range(total_frames))\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, num=num_samples, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame {idx} from {video_path}\")\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not frames:\n",
    "        print(f\"Error: No frames sampled from video {video_path}\")\n",
    "    else:\n",
    "        print(f\"Successfully sampled {len(frames)} frames from {video_path}\")\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def process_videos_to_r2plus1d_embeddings(input_folder: str, output_folder: str, \n",
    "                                         feature_extractor: R2Plus1DFeatureExtractor,\n",
    "                                         num_frames: int = 32):\n",
    "    \"\"\"\n",
    "    Process all videos in a folder and generate R(2+1)D embeddings.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Folder containing input videos\n",
    "        output_folder: Folder to save embeddings\n",
    "        feature_extractor: R(2+1)D feature extractor instance\n",
    "        num_frames: Number of frames to use for each video\n",
    "    \"\"\"\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: Folder does not exist: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith('.mp4'):\n",
    "            print(f\"Skipping non-video file: {fname}\")\n",
    "            continue\n",
    "        \n",
    "        video_path = os.path.join(input_folder, fname)\n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        \n",
    "        # Sample frames from video\n",
    "        frames = sample_frames_from_video(video_path, num_samples=num_frames)\n",
    "        \n",
    "        if frames:\n",
    "            # Extract R(2+1)D features\n",
    "            try:\n",
    "                features = feature_extractor.extract_features(frames)\n",
    "                \n",
    "                # Save the embedding as a .npy file\n",
    "                output_path = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}.npy\")\n",
    "                np.save(output_path, features)\n",
    "                print(f\"Saved R(2+1)D embedding to {output_path} (shape: {features.shape})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {fname}: {e}\")\n",
    "        else:\n",
    "            print(f\"Error: No frames sampled from {fname}\")\n",
    "\n",
    "def l2_normalize(vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform L2 normalization on a vector.\n",
    "    \n",
    "    Args:\n",
    "        vec: Input vector\n",
    "        \n",
    "    Returns:\n",
    "        L2-normalized vector\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm == 0:\n",
    "        return vec\n",
    "    return vec / norm\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    \n",
    "    Args:\n",
    "        vec1: First vector\n",
    "        vec2: Second vector\n",
    "        \n",
    "    Returns:\n",
    "        Cosine similarity value\n",
    "    \"\"\"\n",
    "    # Normalize vectors\n",
    "    vec1_norm = l2_normalize(vec1)\n",
    "    vec2_norm = l2_normalize(vec2)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return np.dot(vec1_norm, vec2_norm)\n",
    "\n",
    "def build_r2plus1d_prototypes(goal_folder: str, nongoal_folder: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build prototypes for goal and non-goal classes using R(2+1)D embeddings.\n",
    "    \n",
    "    Args:\n",
    "        goal_folder: Path to folder containing goal clip embeddings\n",
    "        nongoal_folder: Path to folder containing non-goal clip embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (goal_prototype, nongoal_prototype)\n",
    "    \"\"\"\n",
    "    goal_vecs = []\n",
    "    nongoal_vecs = []\n",
    "\n",
    "    # Load goal embeddings\n",
    "    print(\"Loading goal embeddings...\")\n",
    "    for fname in os.listdir(goal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(goal_folder, fname))\n",
    "            goal_vecs.append(vec)\n",
    "            print(f\"Loaded goal embedding: {fname} (shape: {vec.shape})\")\n",
    "\n",
    "    # Load non-goal embeddings\n",
    "    print(\"Loading non-goal embeddings...\")\n",
    "    for fname in os.listdir(nongoal_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            vec = np.load(os.path.join(nongoal_folder, fname))\n",
    "            nongoal_vecs.append(vec)\n",
    "            print(f\"Loaded non-goal embedding: {fname} (shape: {vec.shape})\")\n",
    "\n",
    "    if not goal_vecs or not nongoal_vecs:\n",
    "        raise ValueError(\"No embeddings found in one or both folders!\")\n",
    "\n",
    "    # Compute mean vectors (prototypes)\n",
    "    proto_goal = np.mean(goal_vecs, axis=0)\n",
    "    proto_nongoal = np.mean(nongoal_vecs, axis=0)\n",
    "\n",
    "    # Normalize prototypes\n",
    "    proto_goal = l2_normalize(proto_goal)\n",
    "    proto_nongoal = l2_normalize(proto_nongoal)\n",
    "\n",
    "    print(f\"Goal prototype shape: {proto_goal.shape}\")\n",
    "    print(f\"Non-goal prototype shape: {proto_nongoal.shape}\")\n",
    "    print(f\"Built prototypes from {len(goal_vecs)} goal and {len(nongoal_vecs)} non-goal samples\")\n",
    "\n",
    "    return proto_goal, proto_nongoal\n",
    "\n",
    "def classify_r2plus1d_clip(clip_embedding: np.ndarray, \n",
    "                          proto_goal: np.ndarray, \n",
    "                          proto_nongoal: np.ndarray, \n",
    "                          threshold: float = 0.0) -> Tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Classify a clip using cosine similarity to prototypes.\n",
    "    \n",
    "    Args:\n",
    "        clip_embedding: R(2+1)D embedding of the clip to classify\n",
    "        proto_goal: Goal class prototype\n",
    "        proto_nongoal: Non-goal class prototype\n",
    "        threshold: Decision threshold\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (predicted_label, similarity_scores)\n",
    "    \"\"\"\n",
    "    # Normalize the clip embedding\n",
    "    clip_norm = l2_normalize(clip_embedding)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    sim_goal = cosine_similarity(clip_norm, proto_goal)\n",
    "    sim_nongoal = cosine_similarity(clip_norm, proto_nongoal)\n",
    "\n",
    "    # Classify based on similarity difference and threshold\n",
    "    difference = sim_goal - sim_nongoal\n",
    "    predicted_label = \"Goal\" if difference > threshold else \"Non-Goal\"\n",
    "    \n",
    "    similarity_scores = {\n",
    "        'sim_goal': sim_goal,\n",
    "        'sim_nongoal': sim_nongoal,\n",
    "        'difference': difference,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "    return predicted_label, similarity_scores\n",
    "\n",
    "def evaluate_r2plus1d_classification(goal_test_folder: str, \n",
    "                                    nongoal_test_folder: str,\n",
    "                                    proto_goal: np.ndarray,\n",
    "                                    proto_nongoal: np.ndarray,\n",
    "                                    threshold: float = 0.0) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate R(2+1)D-based classification on test data.\n",
    "    \n",
    "    Args:\n",
    "        goal_test_folder: Folder containing goal test embeddings\n",
    "        nongoal_test_folder: Folder containing non-goal test embeddings\n",
    "        proto_goal: Goal class prototype\n",
    "        proto_nongoal: Non-goal class prototype\n",
    "        threshold: Decision threshold\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing evaluation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'correct': 0,\n",
    "        'total': 0,\n",
    "        'goal_correct': 0,\n",
    "        'goal_total': 0,\n",
    "        'nongoal_correct': 0,\n",
    "        'nongoal_total': 0,\n",
    "        'predictions': []\n",
    "    }\n",
    "    \n",
    "    # Test goal clips\n",
    "    print(\"\\nTesting goal clips...\")\n",
    "    for fname in os.listdir(goal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(goal_test_folder, fname))\n",
    "            predicted_label, sim_scores = classify_r2plus1d_clip(\n",
    "                test_embedding, proto_goal, proto_nongoal, threshold\n",
    "            )\n",
    "            \n",
    "            is_correct = predicted_label == \"Goal\"\n",
    "            results['goal_total'] += 1\n",
    "            results['total'] += 1\n",
    "            \n",
    "            if is_correct:\n",
    "                results['goal_correct'] += 1\n",
    "                results['correct'] += 1\n",
    "            \n",
    "            result_entry = {\n",
    "                'file': fname,\n",
    "                'true_label': 'Goal',\n",
    "                'predicted_label': predicted_label,\n",
    "                'correct': is_correct,\n",
    "                'similarities': sim_scores\n",
    "            }\n",
    "            results['predictions'].append(result_entry)\n",
    "            \n",
    "            print(f\"File: {fname}\")\n",
    "            print(f\"  True: Goal, Predicted: {predicted_label}\")\n",
    "            print(f\"  Sim Goal: {sim_scores['sim_goal']:.4f}, Sim Non-Goal: {sim_scores['sim_nongoal']:.4f}\")\n",
    "            print(f\"  Difference: {sim_scores['difference']:.4f}, Correct: {is_correct}\")\n",
    "    \n",
    "    # Test non-goal clips\n",
    "    print(\"\\nTesting non-goal clips...\")\n",
    "    for fname in os.listdir(nongoal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(nongoal_test_folder, fname))\n",
    "            predicted_label, sim_scores = classify_r2plus1d_clip(\n",
    "                test_embedding, proto_goal, proto_nongoal, threshold\n",
    "            )\n",
    "            \n",
    "            is_correct = predicted_label == \"Non-Goal\"\n",
    "            results['nongoal_total'] += 1\n",
    "            results['total'] += 1\n",
    "            \n",
    "            if is_correct:\n",
    "                results['nongoal_correct'] += 1\n",
    "                results['correct'] += 1\n",
    "            \n",
    "            result_entry = {\n",
    "                'file': fname,\n",
    "                'true_label': 'Non-Goal',\n",
    "                'predicted_label': predicted_label,\n",
    "                'correct': is_correct,\n",
    "                'similarities': sim_scores\n",
    "            }\n",
    "            results['predictions'].append(result_entry)\n",
    "            \n",
    "            print(f\"File: {fname}\")\n",
    "            print(f\"  True: Non-Goal, Predicted: {predicted_label}\")\n",
    "            print(f\"  Sim Goal: {sim_scores['sim_goal']:.4f}, Sim Non-Goal: {sim_scores['sim_nongoal']:.4f}\")\n",
    "            print(f\"  Difference: {sim_scores['difference']:.4f}, Correct: {is_correct}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    overall_accuracy = results['correct'] / results['total'] if results['total'] > 0 else 0\n",
    "    goal_accuracy = results['goal_correct'] / results['goal_total'] if results['goal_total'] > 0 else 0\n",
    "    nongoal_accuracy = results['nongoal_correct'] / results['nongoal_total'] if results['nongoal_total'] > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({results['correct']}/{results['total']})\")\n",
    "    print(f\"Goal Accuracy: {goal_accuracy:.4f} ({results['goal_correct']}/{results['goal_total']})\")\n",
    "    print(f\"Non-Goal Accuracy: {nongoal_accuracy:.4f} ({results['nongoal_correct']}/{results['nongoal_total']})\")\n",
    "    \n",
    "    results['overall_accuracy'] = overall_accuracy\n",
    "    results['goal_accuracy'] = goal_accuracy\n",
    "    results['nongoal_accuracy'] = nongoal_accuracy\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_with_sklearn_metrics(goal_test_folder: str, \n",
    "                                 nongoal_test_folder: str,\n",
    "                                 proto_goal: np.ndarray,\n",
    "                                 proto_nongoal: np.ndarray,\n",
    "                                 threshold: float = 0.0) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate classification performance using sklearn metrics.\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Test goal clips\n",
    "    print(\"\\nTesting goal clips...\")\n",
    "    for fname in os.listdir(goal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(goal_test_folder, fname))\n",
    "            predicted_label, _ = classify_r2plus1d_clip(test_embedding, proto_goal, proto_nongoal, threshold)\n",
    "            \n",
    "            y_true.append(1)  # True label: Goal\n",
    "            y_pred.append(1 if predicted_label == \"Goal\" else 0)\n",
    "    \n",
    "    # Test non-goal clips\n",
    "    print(\"Testing non-goal clips...\")\n",
    "    for fname in os.listdir(nongoal_test_folder):\n",
    "        if fname.endswith(\".npy\"):\n",
    "            test_embedding = np.load(os.path.join(nongoal_test_folder, fname))\n",
    "            predicted_label, _ = classify_r2plus1d_clip(test_embedding, proto_goal, proto_nongoal, threshold)\n",
    "            \n",
    "            y_true.append(0)  # True label: Non-Goal\n",
    "            y_pred.append(1 if predicted_label == \"Goal\" else 0)\n",
    "    \n",
    "    # Compute metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F₁ Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "\n",
    "def split_embeddings_train_test(input_folder: str, train_folder: str, test_folder: str, \n",
    "                               train_ratio: float = 0.7):\n",
    "    \"\"\"\n",
    "    Split embeddings into train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Folder containing all embeddings\n",
    "        train_folder: Output folder for training embeddings\n",
    "        test_folder: Output folder for test embeddings\n",
    "        train_ratio: Ratio of data to use for training\n",
    "    \"\"\"\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all .npy files\n",
    "    embedding_files = [f for f in os.listdir(input_folder) if f.endswith('.npy')]\n",
    "    random.shuffle(embedding_files)\n",
    "    \n",
    "    # Split files\n",
    "    split_idx = int(len(embedding_files) * train_ratio)\n",
    "    train_files = embedding_files[:split_idx]\n",
    "    test_files = embedding_files[split_idx:]\n",
    "    \n",
    "    # Copy files to respective folders\n",
    "    for file in train_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(train_folder, file)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    for file in test_files:\n",
    "        src = os.path.join(input_folder, file)\n",
    "        dst = os.path.join(test_folder, file)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    print(f\"Split {len(embedding_files)} files: {len(train_files)} train, {len(test_files)} test\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run R(2+1)D-based few-shot learning classification.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    base_path = \"F:/AIM Lab/Experiment/Clips\"\n",
    "    \n",
    "    # CORRECTED: Use the actual video folder paths with Train/Test subdirectories\n",
    "    goal_train_videos = os.path.join(base_path, \"Goal p1\", \"Train\")\n",
    "    goal_test_videos = os.path.join(base_path, \"Goal p1\", \"Test\")\n",
    "    nongoal_train_videos = os.path.join(base_path, \"NoGoal p1\", \"Train\")\n",
    "    nongoal_test_videos = os.path.join(base_path, \"NoGoal p1\", \"Test\")\n",
    "    \n",
    "    # R(2+1)D embedding folders\n",
    "    r2plus1d_base_path = os.path.join(base_path, \"R2Plus1D_Embeddings\")\n",
    "    goal_train_folder = os.path.join(r2plus1d_base_path, \"Goal_Train\")\n",
    "    goal_test_folder = os.path.join(r2plus1d_base_path, \"Goal_Test\")\n",
    "    nongoal_train_folder = os.path.join(r2plus1d_base_path, \"NoGoal_Train\")\n",
    "    nongoal_test_folder = os.path.join(r2plus1d_base_path, \"NoGoal_Test\")\n",
    "    \n",
    "    # Initialize R(2+1)D feature extractor\n",
    "    print(\"Initializing R(2+1)D feature extractor...\")\n",
    "    feature_extractor = R2Plus1DFeatureExtractor()\n",
    "    \n",
    "    # Step 1: Generate R(2+1)D embeddings for train and test videos separately\n",
    "    print(\"\\nStep 1: Generating R(2+1)D embeddings...\")\n",
    "    \n",
    "    print(\"Processing goal training videos...\")\n",
    "    process_videos_to_r2plus1d_embeddings(goal_train_videos, goal_train_folder, feature_extractor)\n",
    "    \n",
    "    print(\"Processing goal test videos...\")\n",
    "    process_videos_to_r2plus1d_embeddings(goal_test_videos, goal_test_folder, feature_extractor)\n",
    "    \n",
    "    print(\"Processing non-goal training videos...\")\n",
    "    process_videos_to_r2plus1d_embeddings(nongoal_train_videos, nongoal_train_folder, feature_extractor)\n",
    "    \n",
    "    print(\"Processing non-goal test videos...\")\n",
    "    process_videos_to_r2plus1d_embeddings(nongoal_test_videos, nongoal_test_folder, feature_extractor)\n",
    "    \n",
    "    # Step 2: Build prototypes from training data\n",
    "    print(\"\\nStep 2: Building prototypes from training data...\")\n",
    "    try:\n",
    "        proto_goal, proto_nongoal = build_r2plus1d_prototypes(goal_train_folder, nongoal_train_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error building prototypes: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Evaluate on test data with different thresholds\n",
    "    print(\"\\nStep 3: Evaluating classification performance...\")\n",
    "    thresholds = [0.0, 0.01, 0.02, 0.05, 0.1]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_threshold = 0\n",
    "    best_results = None\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nTesting with threshold: {threshold}\")\n",
    "        results = evaluate_r2plus1d_classification(\n",
    "            goal_test_folder, nongoal_test_folder, \n",
    "            proto_goal, proto_nongoal, threshold\n",
    "        )\n",
    "        \n",
    "        if results['overall_accuracy'] > best_accuracy:\n",
    "            best_accuracy = results['overall_accuracy']\n",
    "            best_threshold = threshold\n",
    "            best_results = results\n",
    "    \n",
    "    # Step 4: Detailed evaluation with sklearn metrics\n",
    "    print(f\"\\nStep 4: Detailed evaluation with best threshold ({best_threshold})...\")\n",
    "    sklearn_metrics = evaluate_with_sklearn_metrics(\n",
    "        goal_test_folder, nongoal_test_folder,\n",
    "        proto_goal, proto_nongoal, best_threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Best Threshold: {best_threshold}\")\n",
    "    print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "    print(f\"Precision: {sklearn_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {sklearn_metrics['recall']:.4f}\")\n",
    "    print(f\"F₁ Score: {sklearn_metrics['f1_score']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
