{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc53fe45",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'F:\\\\AIM Lab\\\\Experiment\\\\2014-2015' -> 'F:\\\\AIM Lab\\\\Experiment\\\\no video+1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Specify the base directory\u001b[39;00m\n\u001b[0;32m     22\u001b[0m base_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAIM Lab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Root folder\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mrename_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mrename_folders\u001b[1;34m(base_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m new_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno video+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m new_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, new_name)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRenamed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubdir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'F:\\\\AIM Lab\\\\Experiment\\\\2014-2015' -> 'F:\\\\AIM Lab\\\\Experiment\\\\no video+1'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def rename_folders(base_dir):\n",
    "    iteration = 1  # Start iteration counter\n",
    "\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for subdir in dirs:\n",
    "            subdir_path = os.path.join(root, subdir)\n",
    "            target_file = os.path.join(subdir_path, \"2_720p.mkv\")\n",
    "\n",
    "            # Check if the target file exists in the subfolder\n",
    "            if not os.path.exists(target_file):\n",
    "                # Rename the subfolder\n",
    "                new_name = f\"no video+{iteration}\"\n",
    "                new_path = os.path.join(root, new_name)\n",
    "                os.rename(subdir_path, new_path)\n",
    "                print(f\"Renamed: {subdir_path} -> {new_path}\")\n",
    "                iteration += 1\n",
    "\n",
    "# Specify the base directory\n",
    "base_directory = r\"F:\\AIM Lab\\Experiment\"  # Root folder\n",
    "rename_folders(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141571a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv.\n",
      "MoviePy - Writing audio in 2_720pTTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\n",
      "Trimmed video saved as: F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from moviepy import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "def extract_timestamps(json_file):\n",
    "    \"\"\"\n",
    "    Extract timestamps for specific events from the JSON file.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Define the labels to extract\n",
    "    target_labels = {\"Goal\", \"Penalty\", \"Red card\", \"Direct free-kick\", \"Shots on target\"}\n",
    "    timestamps = []\n",
    "\n",
    "    # Extract timestamps for the target labels\n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        if annotation[\"label\"] in target_labels:\n",
    "            game_time = annotation[\"gameTime\"]\n",
    "            minutes, seconds = map(int, game_time.split(\" - \")[1].split(\":\"))\n",
    "            start_time = max(0, (minutes * 60 + seconds) - 3)  # Start time (-3 seconds)\n",
    "            end_time = (minutes * 60 + seconds) + 3  # End time (+3 seconds)\n",
    "            timestamps.append((start_time, end_time))\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "def trim_and_merge_video(video_path, timestamps, output_path):\n",
    "    \"\"\"\n",
    "    Trim the video based on the extracted timestamps and merge the clips.\n",
    "    \"\"\"\n",
    "    # Load the video\n",
    "    video = VideoFileClip(video_path)\n",
    "    clips = []\n",
    "\n",
    "    # Trim the video based on timestamps\n",
    "    for start, end in timestamps:\n",
    "        clip = video.subclipped(start, end)\n",
    "        clips.append(clip)\n",
    "\n",
    "    # Concatenate all clips\n",
    "    final_video = concatenate_videoclips(clips)\n",
    "\n",
    "    # Write the output video\n",
    "    final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    # Close the video objects\n",
    "    video.close()\n",
    "    for clip in clips:\n",
    "        clip.close()\n",
    "\n",
    "# Paths\n",
    "base_folder = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\"\n",
    "json_file = os.path.join(base_folder, \"Labels-v2.json\")\n",
    "video_file = os.path.join(base_folder, \"2_720p.mkv\")\n",
    "output_file = os.path.join(base_folder, \"2_720pT.mkv\")\n",
    "\n",
    "# Extract timestamps and process the video\n",
    "timestamps = extract_timestamps(json_file)\n",
    "if os.path.exists(video_file):\n",
    "    trim_and_merge_video(video_file, timestamps, output_file)\n",
    "    print(f\"Trimmed video saved as: {output_file}\")\n",
    "else:\n",
    "    print(f\"Video file not found: {video_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af8722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1801 frames...\n",
      "Processed 100/1801 frames\n",
      "Processed 200/1801 frames\n",
      "Processed 300/1801 frames\n",
      "Processed 400/1801 frames\n",
      "Processed 500/1801 frames\n",
      "Processed 600/1801 frames\n",
      "Processed 700/1801 frames\n",
      "Processed 800/1801 frames\n",
      "Processed 900/1801 frames\n",
      "Processed 1000/1801 frames\n",
      "Processed 1100/1801 frames\n",
      "Processed 1200/1801 frames\n",
      "Processed 1300/1801 frames\n",
      "Processed 1400/1801 frames\n",
      "Processed 1500/1801 frames\n",
      "Processed 1600/1801 frames\n",
      "Processed 1700/1801 frames\n",
      "Processed 1800/1801 frames\n",
      "Processed video saved as: F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_processed2.mp4\n",
      "Processing 1801 frames...\n",
      "Processed 100/1801 frames\n",
      "Processed 200/1801 frames\n",
      "Processed 300/1801 frames\n",
      "Processed 400/1801 frames\n",
      "Processed 500/1801 frames\n",
      "Processed 600/1801 frames\n",
      "Processed 700/1801 frames\n",
      "Processed 800/1801 frames\n",
      "Processed 900/1801 frames\n",
      "Processed 1000/1801 frames\n",
      "Processed 1100/1801 frames\n",
      "Processed 1200/1801 frames\n",
      "Processed 1300/1801 frames\n",
      "Processed 1400/1801 frames\n",
      "Processed 1500/1801 frames\n",
      "Processed 1600/1801 frames\n",
      "Processed 1700/1801 frames\n",
      "Processed 1800/1801 frames\n",
      "Processed video saved as: F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_processed2_alt.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process the video to:\n",
    "    1. Convert to grayscale.\n",
    "    2. Remove grass and audience areas while preserving the ball.\n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Changed to mp4v for better compatibility\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=False)\n",
    "    \n",
    "    print(f\"Processing {total_frames} frames...\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Convert original frame to HSV for better color detection\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define green grass color range in HSV (more specific range)\n",
    "        lower_green = np.array([35, 40, 40])\n",
    "        upper_green = np.array([85, 255, 255])\n",
    "        grass_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "        # Define ball detection (white/light colored ball)\n",
    "        # Method 1: HSV-based ball detection\n",
    "        lower_ball_hsv = np.array([0, 0, 200])\n",
    "        upper_ball_hsv = np.array([180, 30, 255])\n",
    "        ball_mask_hsv = cv2.inRange(hsv, lower_ball_hsv, upper_ball_hsv)\n",
    "        \n",
    "        # Method 2: Grayscale-based ball detection (bright pixels)\n",
    "        _, ball_mask_gray = cv2.threshold(gray_frame, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Combine both ball detection methods\n",
    "        ball_mask = cv2.bitwise_or(ball_mask_hsv, ball_mask_gray)\n",
    "        \n",
    "        # Apply morphological operations to clean up the ball mask\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        ball_mask = cv2.morphologyEx(ball_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        ball_mask = cv2.morphologyEx(ball_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Define audience areas (you might want to adjust this based on your video)\n",
    "        # More conservative approach: only target very bright, saturated colors\n",
    "        lower_audience = np.array([0, 100, 150])  # More restrictive\n",
    "        upper_audience = np.array([180, 255, 255])\n",
    "        audience_mask = cv2.inRange(hsv, lower_audience, upper_audience)\n",
    "        \n",
    "        # Remove ball pixels from audience mask to prevent ball deletion\n",
    "        audience_mask = cv2.bitwise_and(audience_mask, cv2.bitwise_not(ball_mask))\n",
    "\n",
    "        # Combine grass and audience masks\n",
    "        combined_mask = cv2.bitwise_or(grass_mask, audience_mask)\n",
    "\n",
    "        # Create the final mask: remove grass and audience but keep the ball\n",
    "        # Invert the combined mask to keep the field and ball\n",
    "        keep_mask = cv2.bitwise_not(combined_mask)\n",
    "        \n",
    "        # Ensure ball pixels are always kept (add ball mask to keep_mask)\n",
    "        keep_mask = cv2.bitwise_or(keep_mask, ball_mask)\n",
    "\n",
    "        # Apply the mask to the grayscale frame\n",
    "        processed_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=keep_mask)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Processed video saved as: {output_path}\")\n",
    "\n",
    "def process_video_alternative(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Alternative approach: Use field detection instead of grass removal\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=False)\n",
    "    \n",
    "    print(f\"Processing {total_frames} frames...\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define what to keep (field area + ball)\n",
    "        # Keep the playing field (moderate green) and the ball\n",
    "        lower_field = np.array([35, 30, 30])\n",
    "        upper_field = np.array([85, 255, 200])\n",
    "        field_mask = cv2.inRange(hsv, lower_field, upper_field)\n",
    "        \n",
    "        # Ball detection (white/bright objects)\n",
    "        lower_ball = np.array([0, 0, 180])\n",
    "        upper_ball = np.array([180, 40, 255])\n",
    "        ball_mask = cv2.inRange(hsv, lower_ball, upper_ball)\n",
    "        \n",
    "        # Keep field and ball\n",
    "        keep_mask = cv2.bitwise_or(field_mask, ball_mask)\n",
    "        \n",
    "        # Apply morphological operations to clean up\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        keep_mask = cv2.morphologyEx(keep_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Apply the mask\n",
    "        processed_frame = cv2.bitwise_and(gray_frame, gray_frame, mask=keep_mask)\n",
    "        \n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Processed video saved as: {output_path}\")\n",
    "\n",
    "# Paths\n",
    "input_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\"\n",
    "output_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_processed2.mp4\"\n",
    "\n",
    "# Check if input video exists\n",
    "if os.path.exists(input_video):\n",
    "    # Try the main approach first\n",
    "    process_video(input_video, output_video)\n",
    "    \n",
    "    # If you want to try the alternative approach, uncomment below:\n",
    "    output_video_alt = output_video.replace('.mp4', '_alt.mp4')\n",
    "    process_video_alternative(input_video, output_video_alt)\n",
    "else:\n",
    "    print(f\"Input video not found: {input_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f01f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Optical flow init\u001b[39;00m\n\u001b[0;32m     21\u001b[0m ret, prev_frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 22\u001b[0m prev_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m prev_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(prev_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[0;32m     25\u001b[0m all_keypoints \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# Mediapipe pose setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "# -----------------------\n",
    "\n",
    "# Parameters for HSV grass masking (tweak as needed)\n",
    "lower_green = np.array([35, 40, 40])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "\n",
    "# Load video\n",
    "video_path = \"your_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Optical flow init\n",
    "ret, prev_frame = cap.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "all_keypoints = []\n",
    "all_flow = []\n",
    "\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ---------------------\n",
    "    # 1. Background removal: zero out grass\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    frame[mask > 0] = 0\n",
    "\n",
    "    # ---------------------\n",
    "    # 2. Skeleton extraction\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "    else:\n",
    "        keypoints = [0] * (33 * 4)  # fill with zeros if no detection\n",
    "\n",
    "    all_keypoints.append(keypoints)\n",
    "\n",
    "    # ---------------------\n",
    "    # 3. Optical flow calculation\n",
    "    gray = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, \n",
    "        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    all_flow.append(flow.mean(axis=(0,1)))  # average flow vector per frame\n",
    "\n",
    "    # Update prev frame\n",
    "    prev_gray = gray.copy()\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "\n",
    "# ---------------------\n",
    "# Save features to a single file\n",
    "np.savez(\"video_features.npz\", keypoints=np.array(all_keypoints), flow=np.array(all_flow))\n",
    "print(f\"Saved {frame_idx} frames of features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a57166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing basic heatmap...\n",
      "Processing 1801 frames...\n",
      "Processed 100/1801 frames\n",
      "Processed 200/1801 frames\n",
      "Processed 300/1801 frames\n",
      "Processed 400/1801 frames\n",
      "Processed 500/1801 frames\n",
      "Processed 600/1801 frames\n",
      "Processed 700/1801 frames\n",
      "Processed 800/1801 frames\n",
      "Processed 900/1801 frames\n",
      "Processed 1000/1801 frames\n",
      "Processed 1100/1801 frames\n",
      "Processed 1200/1801 frames\n",
      "Processed 1300/1801 frames\n",
      "Processed 1400/1801 frames\n",
      "Processed 1500/1801 frames\n",
      "Processed 1600/1801 frames\n",
      "Processed 1700/1801 frames\n",
      "Processed 1800/1801 frames\n",
      "Heatmap video saved as: F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_heatmap.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy import VideoFileClip\n",
    "import os\n",
    "\n",
    "def create_football_heatmap_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process football video to remove background and create heatmaps for players, referees, ball, and goal.\n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Initialize background subtractor for grass detection\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "    \n",
    "    # Accumulator for heatmap\n",
    "    heatmap_accumulator = np.zeros((height, width), dtype=np.float32)\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(f\"Processing {total_frames} frames...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "        \n",
    "        # Convert to HSV for better color segmentation\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Define green grass color range in HSV\n",
    "        lower_green = np.array([35, 40, 40])\n",
    "        upper_green = np.array([85, 255, 255])\n",
    "        grass_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        \n",
    "        # Remove advertisement boards (typically at edges and bright colors)\n",
    "        # Define ranges for bright colors (advertisements)\n",
    "        lower_bright = np.array([0, 100, 100])\n",
    "        upper_bright = np.array([180, 255, 255])\n",
    "        bright_mask = cv2.inRange(hsv, lower_bright, upper_bright)\n",
    "        \n",
    "        # Create edge mask for advertisement removal\n",
    "        edge_thickness = 50  # pixels from edge\n",
    "        edge_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        edge_mask[:edge_thickness, :] = 255  # Top edge\n",
    "        edge_mask[-edge_thickness:, :] = 255  # Bottom edge\n",
    "        edge_mask[:, :edge_thickness] = 255  # Left edge\n",
    "        edge_mask[:, -edge_thickness:] = 255  # Right edge\n",
    "        \n",
    "        # Combine masks for background removal\n",
    "        background_mask = cv2.bitwise_or(grass_mask, edge_mask)\n",
    "        background_mask = cv2.bitwise_or(background_mask, bright_mask)\n",
    "        \n",
    "        # Apply morphological operations to clean up mask\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        background_mask = cv2.morphologyEx(background_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        background_mask = cv2.morphologyEx(background_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Create foreground mask (players, referees, ball, goal)\n",
    "        foreground_mask = cv2.bitwise_not(background_mask)\n",
    "        \n",
    "        # Apply Gaussian blur to foreground mask for smoother heatmap\n",
    "        foreground_mask_blur = cv2.GaussianBlur(foreground_mask, (15, 15), 0)\n",
    "        \n",
    "        # Accumulate heatmap data\n",
    "        heatmap_accumulator += foreground_mask_blur.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Create output frame\n",
    "        output_frame = np.zeros_like(frame)\n",
    "        \n",
    "        # Normalize current heatmap for visualization\n",
    "        current_heatmap = heatmap_accumulator / frame_count\n",
    "        current_heatmap_normalized = (current_heatmap * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply colormap to heatmap\n",
    "        heatmap_colored = cv2.applyColorMap(current_heatmap_normalized, cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Combine with foreground mask to show only active areas\n",
    "        foreground_3channel = cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR)\n",
    "        output_frame = cv2.bitwise_and(heatmap_colored, foreground_3channel)\n",
    "        \n",
    "        # Write frame\n",
    "        out.write(output_frame)\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Heatmap video saved as: {output_path}\")\n",
    "\n",
    "# Paths\n",
    "input_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\"\n",
    "output_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_heatmap.mp4\"\n",
    "output_video_advanced = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT_heatmap_advanced.mp4\"\n",
    "\n",
    "# Check if input video exists\n",
    "if os.path.exists(input_video):\n",
    "    print(\"Processing basic heatmap...\")\n",
    "    create_football_heatmap_video(input_video, output_video)\n",
    "\n",
    "else:\n",
    "    print(f\"Input video not found: {input_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "lower_green = np.array([35, 40, 40])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "\n",
    "cap = cv2.VideoCapture(\"your_video.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_video = cv2.VideoWriter(\"debug_output.mp4\", fourcc, 30.0, \n",
    "                            (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "all_keypoints = []\n",
    "all_flow_mean = []\n",
    "all_flow_full = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    frame[mask > 0] = 0\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        # Draw skeleton for debug video\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    else:\n",
    "        keypoints = [0] * (33 * 4)\n",
    "\n",
    "    all_keypoints.append(keypoints)\n",
    "\n",
    "    gray = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, \n",
    "        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    all_flow_mean.append(flow.mean(axis=(0,1)))\n",
    "    all_flow_full.append(flow)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    out_video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "out_video.release()\n",
    "\n",
    "np.savez(\"video_features_full.npz\", \n",
    "    keypoints=np.array(all_keypoints), \n",
    "    flow_mean=np.array(all_flow_mean),\n",
    "    flow_full=np.array(all_flow_full))\n",
    "print(\"Done. Saved debug video and full features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e929f40",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.4 GiB for an array with shape (1799, 720, 1280, 2) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 68\u001b[0m\n\u001b[0;32m     62\u001b[0m pose\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     63\u001b[0m out_video\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     65\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAIM Lab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2014-2015\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvideo_features_full.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     66\u001b[0m     keypoints\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(all_keypoints), \n\u001b[0;32m     67\u001b[0m     flow_mean\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(all_flow_mean),\n\u001b[1;32m---> 68\u001b[0m     flow_full\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_flow_full\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone. Saved debug video and full features.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.4 GiB for an array with shape (1799, 720, 1280, 2) and data type float32"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "lower_green = np.array([35, 40, 40])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "\n",
    "input_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\"\n",
    "output_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\debug_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_video = cv2.VideoWriter(output_video, fourcc, 30.0, \n",
    "                            (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "all_keypoints = []\n",
    "all_flow_mean = []\n",
    "all_flow_full = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    frame[mask > 0] = 0\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        # Draw skeleton for debug video\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    else:\n",
    "        keypoints = [0] * (33 * 4)\n",
    "\n",
    "    all_keypoints.append(keypoints)\n",
    "\n",
    "    gray = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, \n",
    "        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    all_flow_mean.append(flow.mean(axis=(0,1)))\n",
    "    all_flow_full.append(flow)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    out_video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "out_video.release()\n",
    "\n",
    "np.savez(r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\video_features_full.npz\", \n",
    "    keypoints=np.array(all_keypoints), \n",
    "    flow_mean=np.array(all_flow_mean),\n",
    "    flow_full=np.array(all_flow_full))\n",
    "print(\"Done. Saved debug video and full features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3a5b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved debug video and full features.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "lower_green = np.array([35, 40, 40])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "\n",
    "input_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_720pT.mkv\"\n",
    "output_video = r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\debug_output.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_video = cv2.VideoWriter(output_video, fourcc, 30.0, \n",
    "                            (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2RGB)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "all_keypoints = []\n",
    "all_flow_mean = []\n",
    "all_flow_full = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    frame[mask > 0] = 0\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "        # Draw skeleton for debug video\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    else:\n",
    "        keypoints = [0] * (33 * 4)\n",
    "\n",
    "    all_keypoints.append(keypoints)\n",
    "\n",
    "    gray = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, \n",
    "        None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    all_flow_mean.append(flow.mean(axis=(0,1)))\n",
    "    all_flow_full.append(flow)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    out_video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "out_video.release()\n",
    "\n",
    "np.savez(r\"F:\\AIM Lab\\Experiment\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\video_features_full.npz\", \n",
    "    keypoints=np.array(all_keypoints), \n",
    "    flow_mean=np.array(all_flow_mean))\n",
    "print(\"Done. Saved debug video and full features.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
